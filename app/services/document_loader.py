"""Chargement et dÃ©coupage d'un PDF"""
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from typing import List
from ..core.config import settings
import logging

logger = logging.getLogger(__name__)

def load_and_split_pdf(pdf_path=None) -> List[Document]:
    """Charge et dÃ©coupe un PDF en chunks"""
    
    path = Path(pdf_path or settings.PDF_PATH)

    if not path.exists():
        raise FileNotFoundError(f"PDF not found: {path}")

    logger.info(f"ðŸ“„ Loading PDF: {path}")
    
    documents = PyPDFLoader(str(path)).load()
    logger.info(f"ðŸ“– {len(documents)} pages loaded")
    
    # Enrichir mÃ©tadonnÃ©es
    for i, doc in enumerate(documents):
        page_num = i + 1
        doc.metadata['page_number'] = page_num
        doc.metadata['source'] = 'PDF'
        
        # DÃ©tecter chapitre
        content_lower = doc.page_content.lower()
        if 'chapter' in content_lower:
            lines = doc.page_content.split('\n')
            for line in lines:
                if 'chapter' in line.lower() and len(line) < 100:
                    doc.metadata['chapter'] = line.strip()
                    break

    # CHUNKS PLUS PETITS pour meilleure prÃ©cision
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,      # â† RÃ©duit de 500 Ã  300
        chunk_overlap=50,    # â† RÃ©duit de 100 Ã  50
        length_function=len,
        separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]
    )

    chunks = splitter.split_documents(documents)
    logger.info(f"âœ‚ï¸ {len(chunks)} chunks created")
    
    if chunks:
        logger.info(f"ðŸ“ Sample chunk:\n{chunks[0].page_content[:150]}...")
    
    return chunks